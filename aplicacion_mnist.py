
import streamlit as st
from PIL import Image
from tensorflow.keras.preprocessing.image import img_to_array
import numpy as np
import gzip
import pickle


def preprocess_image(image):
    image = image.convert('L')  # Convertir a escala de grises
    image = image.resize((28, 28))
    image_array = img_to_array(image) / 255.0
    image_array = image_array.reshape(1, 28 * 28)  # Ajustar dimensiones para el modelo
    return image_array

def load_model():
    filename = "model_trained_classifierSVC.pkl.gz"
    with gzip.open(filename, 'rb') as f:
        model = pickle.load(f)
    return model

def main():
    st.set_page_config(page_title="Clasificaci√≥n MNIST", layout="wide")
    st.title("üñºÔ∏è Clasificaci√≥n de im√°genes MNIST")
    st.write("""
    ### Selecci√≥n del Mejor Modelo Mediante B√∫squeda de Hiperpar√°metros en diferentes m√©todos de clasificaci√≥n.

    En este an√°lisis, se implement√≥ un proceso iterativo para encontrar el mejor modelo de clasificaci√≥n utilizando el Clasificador Naive Bayes (`GaussianNB`)**, √Årboles de decisi√≥n (`DecisionTreeClassifier`)**, **M√°quinas de Soporte Vectorial (SVM)**, entre otros. Para ello, se realiz√≥ una b√∫squeda de hiperpar√°metros mediante la t√©cnica de **Grid Search con validaci√≥n cruzada**, con el objetivo de optimizar la precisi√≥n del modelo y mejorar su capacidad de generalizaci√≥n.

    El procedimiento inici√≥ con la definici√≥n de un conjunto de hiperpar√°metros a evaluar, los cuales incluyen el **par√°metro de penalizaci√≥n (`C`)**, el **tipo de funci√≥n de n√∫cleo (`kernel`)** y el **par√°metro de control de la variabilidad (`gamma`)**. Estos valores fueron explorados dentro de un espacio de b√∫squeda predefinido que abarc√≥ m√∫ltiples configuraciones.

    Posteriormente, se aplic√≥ **GridSearchCV**, una herramienta de `scikit-learn` que permite probar todas las combinaciones posibles de hiperpar√°metros mediante validaci√≥n cruzada. Esto asegur√≥ que el modelo no solo se ajustara correctamente a los datos de entrenamiento, sino que tambi√©n tuviera un buen desempe√±o en datos de prueba.

    Una vez identificado el mejor conjunto de hiperpar√°metros, el modelo √≥ptimo fue entrenado con la totalidad de los datos de entrenamiento y evaluado sobre el conjunto de prueba. Para medir su desempe√±o, se calcularon m√©tricas clave como la **precisi√≥n (accuracy)**, adem√°s de visualizar su comportamiento mediante una **matriz de confusi√≥n y la curva ROC**.""")

    # Agregar imagen desde un archivo local
    st.image("ACC_SVC.png", caption="Matriz de confusi√≥n", use_column_width=True)
    
    st.markdown("### Sube una imagen y el modelo la clasificar√° en una de las 10 categor√≠as del dataset MNIST.")
    
    st.sidebar.header("Carga de Imagen")
    uploaded_file = st.sidebar.file_uploader("Selecciona una imagen (PNG, JPG, JPEG):", type=["jpg", "png", "jpeg"])
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="Imagen original", use_container_width=True)
        
        preprocessed_image = preprocess_image(image)
        
        with col2:
            st.image(image.convert('L').resize((28, 28)), caption="Imagen preprocesada", use_container_width=True)
        
        if st.sidebar.button("Clasificar imagen"):
            model = load_model()
            prediction = model.predict(preprocessed_image)
            predicted_label = np.argmax(prediction)  # Obtener la clase con mayor probabilidad
            st.sidebar.success(f"üî¢ La imagen fue clasificada como: {predicted_label}, que corresponde al n√∫mero '{predicted_label}'.")

if __name__ == "__main__":
    main()
